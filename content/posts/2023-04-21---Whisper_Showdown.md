---
title: "Whisper Showdown: C++ vs. Native, Speed, Cost, YouTube Transcriptions, and Benchmarks"
date: "2023-04-21T04:35:55.344Z"
template: "post"
draft: false
slug: "whisper-showdown"
category: "AI"
tags:
  - "AI"
  - "Artificial Intelligence"
  - "OpenAI"
  - "Whisper"
  - "Automatic Speech Recognition"
  - "Benchmarks"
description: "Comparing the performance of OpenAI's Whisper ASR model on different CPU and GPU setups."
socialImage: "/media/faces.png"
---

OpenAI's Whisper, a powerful automatic speech recognition (ASR) model, has come a long way since 2022. The once GPU-dependent model now runs on regular CPUs and even Android phones! In my latest Medium article, [Whisper Showdown](https://betterprogramming.pub/whisper-showdown-427ce5f486ea), I dive deep into the performance of the Whisper ASR model on various CPU and GPU setups, evaluating the speed, cost, and efficiency of each.

To achieve this, I tested five different machines/environments, ranging from Apple M1 Pro and M2 Pro CPUs to Nvidia RTX 2080 Ti and A100 GPUs, using Python 3.10.11. I transcribed a popular YouTube video to compare the performance and cost of each setup.

In the article, you'll find:

- Whisper benchmarks and results
- Python/PyTube code to transcribe YouTube videos (CPU native and GPU with PyTorch)
- Python/Matplotlib code to visualize the benchmark results with price/performance logic

Discover how to weigh the trade-offs of speed, cost, and quality when using Whisper and other machine learning models, and explore the detailed benchmark results in the full article:

[Whisper Showdown: C++ vs. Native, Speed, Cost, YouTube Transcriptions, and Benchmarks](https://betterprogramming.pub/whisper-showdown-427ce5f486ea) (published on Better Programming)

<a href="https://betterprogramming.pub/whisper-showdown-427ce5f486ea"><img src="/media/faces.png" alt="Whisper Showdown" width="600"></a>```
